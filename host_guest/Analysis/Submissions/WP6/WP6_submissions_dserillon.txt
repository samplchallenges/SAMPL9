# Results for WP6
#
# This file will be automatically parsed.  It must contain the following seven elements:
# predictions, participant name, participant organization, name of method, software listing, method, method category, and ranked.
# These elements must be provided in the order shown.
# The file name must begin with the word "WP6" and then be followed by an underscore or dash.
#
# FILE FORMAT: All comment lines in this file (which begin with #) will be ignored.
# Please use only UTF-8 characters in the non-comment fields. If your information (e.g. your name, etc.)
# contains a non-UTF-8 character, you may note it in comments near that entry.
#
#
# PREDICTIONS
# Please explicitly describe how you handle ions and pKa effects.
#
# The data in each prediction line should be structured as follows, with all (up to six) numbers in kcal/mol.
# host-guest ID (note that the host varies!), Free energy, free energy SEM, free energy model uncertainty,
# enthalpy, enthalpy SEM, enthalpy model uncertainty
# The free energy, free energy SEM, and free energy model uncertainty are REQUIRED.
# The corresponding quantities for binding enthalpy are optional.
#
# Note that the "model uncertainty" should be your estimate of ACCURACY of this particular approach
# for the compound considered.
#
#
# The list of predictions must begin with the "Prediction:" keyword, as illustrated here.
Predictions:
WP6-G1, -8.47, 0.57, 0.61, 0.0, 0.0, 0.0
WP6-G2, -11.39, 0.57, 0.61, 0.0, 0.0, 0.0
WP6-G3, -7.84, 0.57, 0.61, 0.0, 0.0, 0.0
WP6-G4, -8.35, 0.57, 0.61, 0.0, 0.0, 0.0
WP6-G5, -5.20, 0.57, 0.61, 0.0, 0.0, 0.0
WP6-G6, -6.99, 0.57, 0.61, 0.0, 0.0, 0.0
WP6-G7, -7.64, 0.57, 0.61, 0.0, 0.0, 0.0
WP6-G8, -9.53, 0.57, 0.61, 0.0, 0.0, 0.0
WP6-G9, -8.81, 0.57, 0.61, 0.0, 0.0, 0.0
WP6-G10, -10.47, 0.57, 0.61, 0.0, 0.0, 0.0
WP6-G11, -7.16, 0.57, 0.61, 0.0,  0.0, 0.0
WP6-G12, -6.38, 0.57, 0.61, 0.0, 0.0, 0.0
WP6-G13, -10.17, 0.57, 0.61, 0.0, 0.0, 0.0

#
#
# Please list your name, using only UTF-8 characters as described above. The "Participant name:" entry is required.
Participant name:
Dylan SERILLON
#
#
# Please list your organization/affiliation, using only UTF-8 characters as described above.
Participant organization:
University of Barcelona
#
#
# Please provide a brief (40 character limit) informal yet informative name of the method used.
# If using an MD-based method we suggest using the format: Method/EnergyModel/WaterModel/Sampling/[Additional-details-here] , though your name must respect the 40 character limit.
# otherwise you may create your own following the sample text; please edit to your taste.
# The "Name:" keyword is required, as shown here.
# 40 character limit.
Name:
MACHINE-LEARNING/NNET/DRAGON-descriptors
#
# All major software packages used and their versions
# Following is sample text; please edit to your taste.
# The "Software:" keyword is required.
Software:
xtb Version 6.1 
Gromacs Versions 2018.1
Open Babel 2.3.2
AutoDock Vina 1.1.2
MOE Version 2018
chimera production version 1.13.1
VMD for LINUXAMD64, version 1.9.3
#
# Methodology and computational details.
# Level of detail should be at least that used in a publication.
# Please include the values of key parameters, with units, and explain how any
# statistical uncertainties were estimated.
# Use as many lines of text as you need.
# Please explicitly describe how you handle ions (e.g. counterions) and pKa effects
# Following is sample text; please edit to your taste.
# All text following the "Method:" keyword will be regarded as part of your free text methods description.
Method:
SUBMISSION #1  -- RANKED SUBMISSION -- NEURAL NETWORK


Free binding energy prediction using machine learning methods:

1) All the binding data from the Binding Database have been extracted and parsed. All the guest involved in the BindingDB and SAMPL(s) challenges are reconstructed in two steps from SMILES using obabel & CORINA : 
(i) generating 150 3D conformers based on Genetic-Algorithm 
(ii) and the selecting the lowest energy conformers. 
This conformers are then minimized at semi empirical level using xtb-GFN2B giving us an optimized 3D structure. 
The guest from SAMPL6 - SAMPL7 and SAMPL8-DRUG-ABUSE challenges are extracted from repository and only minimized at semi empirical level using xtb-GFN2B giving us an optimized 3D structure. 
807 structures in total are extracted following this approach.

The same methods is used to reconstruct the hosts. In total, 29 different HOSTs are extracted and constructed from SMILES provided by the binding-DB following the same protocol.    
- For the hosts: BDBM197280, BDBM197287, BDBM197309, BDBM197310, BDBM36281 from the previous SAMPL challenges, SMILES reconstruction failed and we had to extract the 3D structure from different SAMPL-repositories followed by minimization at semi empirical level using xtb-GFN2B giving us an optimized 3D structure. 
- BDBM36250 as well was impossible to reconstruct from SMILES, the cyclodextrine was so extracted from 4J3U pdb code that were structurally close, and manually modified with molecular builder, then minimized at semi empirical level with same procedure as before.
2) For both host and Guest structures, the DRAGON molecular descriptors are calculated.
3) The descriptors of the Guest-dataset and the Host-dataset are reduced separatly using the R software with different approaches: a) deleting the descriptors that have a near zero variance using Caret package ; b) deleting the most correlated descriptors using Caret package ; c) using principal component analysis (PCA) to combine descriptors that explain the most the variability.
4) Host-dataset and Guest-dataset are merged to form the final dataset where each lines correspond to a guest interacting with a specific host.

In order to predict the binding free energy, several machine learning models using regression are used: Neural network, knn, polynomial SVM and random forest. By modifying the parameters and using a repeated 10-fold cross validation on those ML models, thousands of different models are generated (respectively 186.500 nnet, 245.700 rf, 54.600 rf and 20 knn).
Both 30/70, 25/75 and 15/85 data partition were tested and our prediction and 15/85 partition is the one selected for the prediction, resulting in a set of 687 cases for training and 120 cases for the test set.

Our bestmodel, used to make predictions on SAMPL9, is a neural network using "nnet" function, which provided a TrainRMSE=0.57, TrainRsquare=0.92, TrainMAE=0.30 performances for trainingset and RMSE=0.61, Rsquare=0.93 and MAE=0.34 for the Testset, suggesting that the prediction is not excessively biased by overtraining.
#
#
# METHOD CATEGORY SECTION
#
# State which method category your prediction method is better described as:
# `Alchemical`, `Quantum`, `Other Physical` `Empirical`, `Mixed`, or `Other`.
# Pick only one category label.
# The `Category:` keyword is required.
Category:
machine learning
#
# All submissions must either be ranked or non-ranked.
# Only one ranked submission per participant is allowed.
# Multiple ranked submissions from the same participant will not be judged.
# Non-ranked submissions are accepted so we can verify that they were made before the deadline.
# The "Ranked:" keyword is required, and expects a Boolean value (True/False)
Ranked:
True